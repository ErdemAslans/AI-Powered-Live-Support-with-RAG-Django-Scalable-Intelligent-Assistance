{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyMg5b/L0ovkfmqX2zHGUbjo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ErdemAslans/AI-Powered-Live-Support-with-RAG-Django-Scalable-Intelligent-Assistance/blob/main/Multidisease_Anaylsis_Platform.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!!pip install  segmentation_models_pytorch\n",
        "!pip install monai\n",
        "!pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gweJrvNzmN4m",
        "outputId": "aef585aa-b28d-46f2-8a8f-044f025cbdb5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting monai\n",
            "  Downloading monai-1.4.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.24 in /usr/local/lib/python3.10/dist-packages (from monai) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from monai) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.9->monai) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->monai) (3.0.2)\n",
            "Downloading monai-1.4.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: monai\n",
            "Successfully installed monai-1.4.0\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (0.9.7)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.1+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.27.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.7->timm) (1.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9E9uHFSmmdhc",
        "outputId": "d5b57c5b-6c79-4751-be5a-034bac547149"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.25.0)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.13.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (11.0.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.36.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.12.12)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyWavelets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_KczuLJmexi",
        "outputId": "10efc59b-78a0-4ba1-b693-f237e5c8e60b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyWavelets\n",
            "  Downloading pywavelets-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from PyWavelets) (1.26.4)\n",
            "Downloading pywavelets-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m4.2/4.5 MB\u001b[0m \u001b[31m126.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyWavelets\n",
            "Successfully installed PyWavelets-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bm3d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-J3BdTKmgsa",
        "outputId": "75bdcc7b-e7c0-4d40-8017-95290ecd4fd0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bm3d\n",
            "  Downloading bm3d-4.0.3-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting bm4d>=4.2.5 (from bm3d)\n",
            "  Downloading bm4d-4.2.5-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bm4d>=4.2.5->bm3d) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from bm4d>=4.2.5->bm3d) (1.13.1)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.10/dist-packages (from bm4d>=4.2.5->bm3d) (1.8.0)\n",
            "Downloading bm3d-4.0.3-py3-none-any.whl (10 kB)\n",
            "Downloading bm4d-4.2.5-py3-none-any.whl (862 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m862.0/862.0 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bm4d, bm3d\n",
            "Successfully installed bm3d-4.0.3 bm4d-4.2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9hO4B52whFe",
        "outputId": "766a7bb7-d98f-4d8b-f5f7-54c15739fd65"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.9.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.5.2 (from gradio)\n",
            "  Downloading gradio_client-1.5.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.3)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.8.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.45.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.2->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.2->gradio) (14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.27.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.9.1-py3-none-any.whl (57.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.5.2-py3-none-any.whl (320 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.4/320.4 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.8.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m116.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.6 ffmpy-0.5.0 gradio-5.9.1 gradio-client-1.5.2 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.20 ruff-0.8.6 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.41.3 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afzI7YTaG2On",
        "outputId": "10445b77-808c-4397-a3aa-0237aa39d469"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gradio as gr\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import cv2\n",
        "from skimage.transform import resize\n",
        "from skimage import exposure\n",
        "import pywt\n",
        "from skimage.restoration import denoise_tv_chambolle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import timm\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "from PIL import Image\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.ERROR)"
      ],
      "metadata": {
        "id": "CRSqBGSU5S6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CBAMBlock(nn.Module):\n",
        "    def __init__(self, channels, reduction=16):\n",
        "        super(CBAMBlock, self).__init__()\n",
        "        self.channel_attention = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(channels, channels // reduction, kernel_size=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(channels // reduction, channels, kernel_size=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.spatial_attention = nn.Sequential(\n",
        "            nn.Conv2d(2, 1, kernel_size=7, padding=3),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        ca = self.channel_attention(x)\n",
        "        x = x * ca\n",
        "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        sa = torch.cat([avg_out, max_out], dim=1)\n",
        "        sa = self.spatial_attention(sa)\n",
        "        x = x * sa\n",
        "        return x\n",
        "\n",
        "class MultiScaleFeatureFusion(nn.Module):\n",
        "    def __init__(self, embed_dim, num_classes=1, dropout_rate=0.1):\n",
        "        super(MultiScaleFeatureFusion, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(embed_dim, embed_dim // 2, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(embed_dim, embed_dim // 2, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(embed_dim, embed_dim // 2, kernel_size=3, padding=1)\n",
        "        self.conv_pred = nn.Conv2d(embed_dim // 2, num_classes, kernel_size=1)\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "\n",
        "        nn.init.kaiming_normal_(self.conv1.weight)\n",
        "        nn.init.kaiming_normal_(self.conv2.weight)\n",
        "        nn.init.kaiming_normal_(self.conv3.weight)\n",
        "        nn.init.kaiming_normal_(self.conv_pred.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = F.interpolate(self.conv1(x), size=(x.shape[2], x.shape[3]), mode='bilinear', align_corners=False)\n",
        "        x2 = self.conv2(x)\n",
        "        x3 = F.interpolate(self.conv3(x), size=(x.shape[2], x.shape[3]), mode='bilinear', align_corners=False)\n",
        "        fused = x1 + x2 + x3\n",
        "        fused = self.dropout(fused)\n",
        "        output = self.conv_pred(fused)\n",
        "        return output\n",
        "\n",
        "class ViTFeatureExtractor(nn.Module):\n",
        "    def __init__(self, dropout_rate=0.2):\n",
        "        super(ViTFeatureExtractor, self).__init__()\n",
        "        self.vit = timm.create_model('vit_base_patch16_224', pretrained=True, drop_rate=dropout_rate, drop_path_rate=0.2)\n",
        "        self.vit.head = nn.Identity()\n",
        "        self.embed_dim = self.vit.embed_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.vit.forward_features(x)\n",
        "        return x\n",
        "\n",
        "class SegFormerDecoderWithAttention(nn.Module):\n",
        "    def __init__(self, embed_dim, num_classes=1, patch_size=16, dropout_rate=0.4):\n",
        "        super(SegFormerDecoderWithAttention, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "        self.num_patches_side = 224 // self.patch_size\n",
        "        self.linear_fuse = nn.Linear(embed_dim, embed_dim)\n",
        "        self.conv_pred = nn.Conv2d(embed_dim, num_classes, kernel_size=1)\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "        self.cbam = CBAMBlock(embed_dim)\n",
        "        self.multi_scale_fusion = MultiScaleFeatureFusion(embed_dim, num_classes, dropout_rate)\n",
        "        nn.init.kaiming_normal_(self.linear_fuse.weight)\n",
        "        nn.init.kaiming_normal_(self.conv_pred.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        x = x[:, 1:, :]\n",
        "        x = self.linear_fuse(x)\n",
        "        x = x.transpose(1, 2).contiguous().view(B, C, self.num_patches_side, self.num_patches_side)\n",
        "        x = F.interpolate(x, size=(224, 224), mode='bilinear', align_corners=False)\n",
        "        x = self.cbam(x)\n",
        "        x = self.multi_scale_fusion(x)\n",
        "        return x\n",
        "\n",
        "class ViT_SegFormer_Model(nn.Module):\n",
        "    def __init__(self, dropout_rate=0.2):\n",
        "        super(ViT_SegFormer_Model, self).__init__()\n",
        "        self.vit = ViTFeatureExtractor(dropout_rate)\n",
        "        self.decoder = SegFormerDecoderWithAttention(embed_dim=self.vit.embed_dim, dropout_rate=dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.vit(x)\n",
        "        output = self.decoder(features)\n",
        "        return output"
      ],
      "metadata": {
        "id": "tNokkpNg5J98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomViT(nn.Module):\n",
        "    def __init__(self, pretrained_vit, num_classes):\n",
        "        super(CustomViT, self).__init__()\n",
        "        self.vit = pretrained_vit\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.fc = nn.Linear(pretrained_vit.heads[0].in_features, num_classes)\n",
        "        self.vit.heads[0] = self.fc\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.vit(x)\n",
        "        x = self.dropout(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "oZol3oqj5PDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yiv4QKYve0HY"
      },
      "outputs": [],
      "source": [
        "def enhance_contrast(image, clip_limit=0.6, tile_grid_size=(32,32), gamma=0.3):\n",
        "    min_val = np.min(image)\n",
        "    max_val = np.max(image)\n",
        "    if max_val - min_val == 0:\n",
        "        image = np.zeros_like(image)\n",
        "    else:\n",
        "        image = (image - min_val) / (max_val - min_val)\n",
        "\n",
        "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
        "    image = clahe.apply((image * 255).astype(np.uint8)) / 255.0\n",
        "\n",
        "    inv_gamma = 1.0 / gamma\n",
        "    table = np.array([(i / 255.0) ** inv_gamma * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
        "    image = cv2.LUT((image * 255).astype(np.uint8), table).astype(np.float32) / 255\n",
        "\n",
        "    laplacian = cv2.Laplacian(image.astype(np.float64), cv2.CV_64F)\n",
        "    laplacian = np.clip(laplacian, 0, 1)\n",
        "    laplacian_weight = 0.33\n",
        "    enhanced_image = image + laplacian_weight * laplacian\n",
        "    enhanced_image = np.clip(enhanced_image, 0, 1)\n",
        "    return enhanced_image\n",
        "\n",
        "def apply_nlm_denoising(image):\n",
        "    denoised_image = cv2.fastNlMeansDenoising(np.uint8(image * 255), None, h=10, templateWindowSize=7, searchWindowSize=21)\n",
        "    denoised_image = denoised_image.astype(np.float32) / 255.0\n",
        "    return denoised_image\n",
        "\n",
        "def apply_wavelet_denoising(image):\n",
        "    coeffs = pywt.wavedec2(image, 'haar', level=2)\n",
        "    coeffs = list(coeffs)\n",
        "    coeffs[1:] = [tuple(pywt.threshold(c, value=0.1, mode='soft') for c in level) for level in coeffs[1:]]\n",
        "    denoised_image = pywt.waverec2(coeffs, 'haar')\n",
        "    if denoised_image.shape != image.shape:\n",
        "        denoised_image = resize(denoised_image, image.shape, mode='reflect', anti_aliasing=True)\n",
        "    return denoised_image\n",
        "\n",
        "def apply_total_variation_denoising(image):\n",
        "    denoised_image = denoise_tv_chambolle(image, weight=0.1)\n",
        "    return denoised_image\n",
        "\n",
        "def process_single_nii(image_nii, mask_nii, view, slice_idx, target_size=(224,224)):\n",
        "    img = image_nii.get_fdata()\n",
        "    if mask_nii is not None:\n",
        "        mask = mask_nii.get_fdata()\n",
        "    else:\n",
        "        mask = np.zeros_like(img)\n",
        "\n",
        "    if view == 'sagittal':\n",
        "        max_slices = img.shape[0]\n",
        "        img_slice = img[slice_idx, :, :] if slice_idx < max_slices else img[max_slices//2,:,:]\n",
        "        mask_slice = mask[slice_idx, :, :] if slice_idx < max_slices else mask[max_slices//2,:,:]\n",
        "    elif view == 'coronal':\n",
        "        max_slices = img.shape[1]\n",
        "        img_slice = img[:, slice_idx, :] if slice_idx < max_slices else img[:, max_slices//2,:]\n",
        "        mask_slice = mask[:, slice_idx, :] if slice_idx < max_slices else mask[:, max_slices//2,:]\n",
        "    elif view == 'axial':\n",
        "        max_slices = img.shape[2]\n",
        "        img_slice = img[:, :, slice_idx] if slice_idx < max_slices else img[:,:,max_slices//2]\n",
        "        mask_slice = mask[:, :, slice_idx] if slice_idx < max_slices else mask[:,:,max_slices//2]\n",
        "\n",
        "    img_slice = resize(img_slice, target_size, mode='reflect', anti_aliasing=True)\n",
        "    mask_slice = resize(\n",
        "        mask_slice, target_size, mode='reflect', anti_aliasing=False,\n",
        "        order=0, preserve_range=True\n",
        "    )\n",
        "\n",
        "    img_slice = enhance_contrast(img_slice)\n",
        "    img_slice = apply_nlm_denoising(img_slice)\n",
        "    img_slice = apply_wavelet_denoising(img_slice)\n",
        "    img_slice = apply_total_variation_denoising(img_slice)\n",
        "\n",
        "    mask_slice = (mask_slice > 0.05).astype(np.float32)\n",
        "\n",
        "    highlight_factor = 1.8\n",
        "    darken_factor = 0.8\n",
        "    img_slice_masked = img_slice * mask_slice * highlight_factor\n",
        "    img_slice_non_masked = img_slice * (1 - mask_slice) * darken_factor\n",
        "    img_slice = img_slice_masked + img_slice_non_masked\n",
        "    img_slice = np.clip(img_slice, 0, 1).astype(np.float32)\n",
        "\n",
        "    return img_slice, mask_slice\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_albumentations_transform():\n",
        "    transform = A.Compose([\n",
        "        A.Resize(224, 224),\n",
        "        A.HorizontalFlip(),\n",
        "        A.RandomCrop(224, 224),\n",
        "        A.CoarseDropout(max_holes=8, max_height=16, max_width=16, fill_value=0),\n",
        "        A.RandomBrightnessContrast(p=0.2),\n",
        "        A.ShiftScaleRotate(p=0.2),\n",
        "        A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
        "        ToTensorV2()\n",
        "    ])\n",
        "    return transform\n",
        "\n",
        "def process_pulmonary_image_specific(image, augmentation_pipeline):\n",
        "    try:\n",
        "        augmented = augmentation_pipeline(image=image)\n",
        "        image_transformed = augmented['image']\n",
        "        return image_transformed\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Pulmonary hypertension preprocessing error: {e}\")\n",
        "        return None\n",
        "\n"
      ],
      "metadata": {
        "id": "IWcM3QXT5fHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "tumor_model = ViT_SegFormer_Model(dropout_rate=0.2).to(device)\n",
        "tumor_weight_path = \"/content/drive/MyDrive/Tumor/best_model.pth\"\n",
        "try:\n",
        "    state_dict_tumor = torch.load(tumor_weight_path, map_location=device)\n",
        "    tumor_model.load_state_dict(state_dict_tumor)\n",
        "    tumor_model.eval()\n",
        "    print(\"Breast Cancer Segmentation model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading Breast Cancer Segmentation model: {e}\")\n",
        "\n",
        "pretrained_vit = torchvision.models.vit_b_16(weights=torchvision.models.ViT_B_16_Weights.DEFAULT).to(device)\n",
        "\n",
        "pulmonary_model = CustomViT(pretrained_vit, num_classes=4).to(device)\n",
        "pulmonary_weight_path = \"/content/drive/MyDrive/Pulmonary_Hypertension/best_model.pth\"\n",
        "try:\n",
        "    state_dict_pulmonary = torch.load(pulmonary_weight_path, map_location=device)\n",
        "    pulmonary_model.load_state_dict(state_dict_pulmonary)\n",
        "    pulmonary_model.eval()\n",
        "    print(\"Pulmonary Hypertension Analysis model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading Pulmonary Hypertension Analysis model: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "8k_jiDHq5iOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_tumor_image(image_file, mask_file, view, slice_idx):\n",
        "    try:\n",
        "        if not image_file:\n",
        "            raise ValueError(\"Image file not uploaded.\")\n",
        "\n",
        "        image_nii = nib.load(image_file.name)\n",
        "        mask_nii = nib.load(mask_file.name) if mask_file and mask_file.name else None\n",
        "\n",
        "        img_slice, mask_slice = process_single_nii(image_nii, mask_nii, view, slice_idx, target_size=(224,224))\n",
        "\n",
        "        img_tensor = torch.from_numpy(img_slice).unsqueeze(0).unsqueeze(0)\n",
        "        img_tensor = img_tensor.repeat(1, 3, 1, 1)\n",
        "        img_tensor = img_tensor.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = tumor_model(img_tensor)\n",
        "            pred_prob = torch.sigmoid(logits)\n",
        "            pred_mask = (pred_prob > 0.5).float()\n",
        "\n",
        "        pred_mask_np = pred_mask.cpu().squeeze().numpy()\n",
        "\n",
        "        return (img_slice, pred_mask_np)\n",
        "    except FileNotFoundError as e:\n",
        "        logging.error(f\"File not found: {e}\")\n",
        "        return \"File not found.\", \"File not found.\"\n",
        "    except ValueError as e:\n",
        "        logging.error(f\"Value error: {e}\")\n",
        "        return \"Invalid input.\", \"Invalid input.\"\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Unexpected error: {e}\")\n",
        "        return \"An error occurred.\", \"An error occurred.\"\n",
        "\n",
        "def process_pulmonary_image(image):\n",
        "    try:\n",
        "        if image is None:\n",
        "            raise ValueError(\"Image not uploaded.\")\n",
        "\n",
        "        if isinstance(image, np.ndarray):\n",
        "            image = Image.fromarray(image.astype('uint8'))\n",
        "\n",
        "        augmentation_pipeline = get_albumentations_transform()\n",
        "\n",
        "        image_transformed = process_pulmonary_image_specific(np.array(image), augmentation_pipeline)\n",
        "        if image_transformed is None:\n",
        "            raise ValueError(\"Pulmonary hypertension preprocessing failed.\")\n",
        "\n",
        "        img_tensor = image_transformed.unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = pulmonary_model(img_tensor)\n",
        "            probabilities = torch.softmax(outputs, dim=1)\n",
        "            predicted_class = torch.argmax(probabilities, dim=1).item()\n",
        "            confidence = probabilities[0][predicted_class].item()\n",
        "\n",
        "        class_names = ['Normal', 'Mild PH', 'Moderate PH', 'Severe PH']\n",
        "        prediction = class_names[predicted_class]\n",
        "\n",
        "        return prediction, f\"{confidence:.2%}\"\n",
        "    except ValueError as e:\n",
        "        logging.error(f\"Value error: {e}\")\n",
        "        return \"Invalid input.\", \"0.00%\"\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Unexpected error: {e}\")\n",
        "        return \"An error occurred.\", \"0.00%\"\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Medical Image Analysis System\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        with gr.Tab(\"Breast Cancer Segmentation\"):\n",
        "            with gr.Row():\n",
        "                image_input = gr.File(label=\"NIfTI Image File (.nii or .nii.gz)\", file_count=\"single\")\n",
        "                mask_input = gr.File(label=\"Mask File (Optional)\", file_count=\"single\")\n",
        "            view_choice = gr.Dropdown(\n",
        "                choices=[\"sagittal\", \"coronal\", \"axial\"],\n",
        "                value=\"axial\",\n",
        "                label=\"View Axis\"\n",
        "            )\n",
        "            slice_choice = gr.Slider(\n",
        "                minimum=0,\n",
        "                maximum=200,\n",
        "                step=1,\n",
        "                value=50,\n",
        "                label=\"Slice Number\"\n",
        "            )\n",
        "            tumor_button = gr.Button(\"Perform Segmentation\")\n",
        "            output_image = gr.Image(label=\"Processed Image\")\n",
        "            output_mask = gr.Image(label=\"Segmentation Mask\")\n",
        "\n",
        "        with gr.Tab(\"Pulmonary Hypertension Analysis\"):\n",
        "            ph_image_input = gr.Image(label=\"Tomography Image\")\n",
        "            ph_button = gr.Button(\"Perform PH Analysis\")\n",
        "            with gr.Row():\n",
        "                ph_prediction = gr.Label(label=\"Prediction\")\n",
        "                ph_confidence = gr.Label(label=\"Confidence Score\")\n",
        "\n",
        "    tumor_button.click(\n",
        "        fn=process_tumor_image,\n",
        "        inputs=[image_input, mask_input, view_choice, slice_choice],\n",
        "        outputs=[output_image, output_mask]\n",
        "    )\n",
        "\n",
        "    ph_button.click(\n",
        "        fn=process_pulmonary_image,\n",
        "        inputs=ph_image_input,\n",
        "        outputs=[ph_prediction, ph_confidence]\n",
        "    )\n",
        "\n",
        "demo.launch(debug=True, share=True)"
      ],
      "metadata": {
        "id": "GR9p6HP57MAm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}